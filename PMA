import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from keras.models import Sequential
from keras.layers import Dense
from google.colab import files
uploaded = files.upload()


data = pd.read_csv('brca.csv')

# Separate features and target variable
X = data.drop(columns=['y'])
y = data['y']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Convert string labels to numerical labels
y_train = y_train.replace({'B': 0, 'M': 1})
y_test = y_test.replace({'B': 0, 'M': 1})

# Build the neural network model
model = Sequential()
model.add(Dense(30, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(15, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile and train the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)

# Evaluate the model
# Predict on test data
y_pred = (model.predict(X_test) > 0.5).astype("int32")

# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

# Display results
print(f'Accuracy Score: {accuracy}')
print(f'F1 Score: {f1}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')

!pip install --upgrade scikit-learn  # Upgrade scikit-learn to the latest version
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, make_scorer
from keras.models import Sequential
from keras.layers import Dense
from scikeras.wrappers import KerasClassifier  # Import KerasClassifier

# Load the data (assuming 'brca.csv' is available)
data = pd.read_csv('brca.csv')

# Separate features and target variable
X = data.drop(columns=['y'])  # Define X here
y = data['y']

# Convert string labels to numerical labels
y = y.replace({'B': 0, 'M': 1})

def create_model():
    model = Sequential()
    model.add(Dense(30, input_dim=X.shape[1], activation='relu'))
    model.add(Dense(15, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Langkah 5: Cross-Validation
# Membungkus model menggunakan KerasClassifier
model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)

# Membuat skorer untuk metrik evaluasi
scorers = {
    'accuracy': make_scorer(accuracy_score),
    'f1': make_scorer(f1_score),
    'precision': make_scorer(precision_score),
    'recall': make_scorer(recall_score)
}

# Melakukan 6-fold cross-validation
kf = KFold(n_splits=6, shuffle=True, random_state=42)
results = {metric: cross_val_score(model, X, y, cv=kf, scoring=scorer) for metric, scorer in scorers.items()}

# Menampilkan hasil rata-rata dan standar deviasi untuk setiap metrik
for metric, scores in results.items():
    print(f'{metric.capitalize()} Score: Mean={scores.mean():.4f}, Std={scores.std():.4f}')

# Importing necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import Pipeline

# Importing classifiers
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

# Loading data
# Assumption: The data is in a CSV file. Replace 'data.csv' with your actual file path.
df = pd.read_csv('brca.csv')

# Splitting the data into features (X) and target (y)
X = df.drop('y', axis=1)
y = df['y']

# Scaling the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# List of classifiers and their respective parameter grids
classifiers = [
    (LogisticRegression(), {
        'logisticregression__C': [0.1, 1, 10, 100],
        'logisticregression__solver': ['liblinear']
    }),
    (RandomForestClassifier(), {
        'randomforestclassifier__n_estimators': [10, 50, 100],
        'randomforestclassifier__max_features': ['auto', 'sqrt', 'log2'],
        'randomforestclassifier__max_depth': [4, 6, 8]
    }),
    (SVC(), {
        'svc__C': [0.1, 1, 10, 100],
        'svc__gamma': [1, 0.1, 0.01, 0.001],
        'svc__kernel': ['rbf', 'linear']
    }),
    (KNeighborsClassifier(), {
        'kneighborsclassifier__n_neighbors': [3, 5, 7, 9],
        'kneighborsclassifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']
    }),
    (DecisionTreeClassifier(), {
        'decisiontreeclassifier__max_depth': [2, 4, 6, 8, 10],
        'decisiontreeclassifier__min_samples_split': [2, 5, 10]
    })
]

# Function to perform hyperparameter tuning and evaluation
def hyperparameter_tuning(classifier, param_grid):
    pipe = Pipeline([(classifier.__class__.__name__.lower(), classifier)])

    # Grid Search
    grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=6, n_jobs=-1, scoring='accuracy')
    grid_search.fit(X_scaled, y)

    # Randomized Search
    randomized_search = RandomizedSearchCV(pipe, param_distributions=param_grid, n_iter=20, cv=6, n_jobs=-1, scoring='accuracy', random_state=42)
    randomized_search.fit(X_scaled, y)

    return {
        'grid_search': {
            'best_score': grid_search.best_score_,
            'best_params': grid_search.best_params_
        },
        'randomized_search': {
            'best_score': randomized_search.best_score_,
            'best_params': randomized_search.best_params_
        }
    }

# Performing hyperparameter tuning for each classifier
results = {}
for classifier, param_grid in classifiers:
    classifier_name = classifier.__class__.__name__
    results[classifier_name] = hyperparameter_tuning(classifier, param_grid)

# Displaying the results
for classifier_name, result in results.items():
    print(f"{classifier_name}:")
    print(f"  Grid Search Best Score: {result['grid_search']['best_score']}")
    print(f"  Grid Search Best Params: {result['grid_search']['best_params']}")
    print(f"  Randomized Search Best Score: {result['randomized_search']['best_score']}")
    print(f"  Randomized Search Best Params: {result['randomized_search']['best_params']}")
    print("\n")
